{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57ef6bb4-19bd-4431-a65a-5ffd5e776118",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing asr_api2.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile asr_api2.py\n",
    "\n",
    "import io\n",
    "import torch\n",
    "import torchaudio\n",
    "from fastapi import FastAPI, File, UploadFile, HTTPException, status\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
    "import uvicorn\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-large-960h\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-large-960h\")\n",
    "\n",
    "@app.get(\"/ping\")\n",
    "def ping():\n",
    "    \"\"\"\n",
    "    Simple health check endpoint\n",
    "    Returns 'pong' if the service is running.\n",
    "    \"\"\"\n",
    "    return \"pong\"\n",
    "\n",
    "@app.post(\"/asr\")\n",
    "async def transcribe_audio(file: UploadFile = File(...)):\n",
    "    \"\"\"\n",
    "    Endpoint: /asr\n",
    "    Accepts an MP3 audio file via multipart/form-data.\n",
    "    Returns a JSON response with 'transcription' and 'duration'.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Check if a file was uploaded\n",
    "    if not file:\n",
    "        raise HTTPException(\n",
    "            status_code=status.HTTP_400_BAD_REQUEST,\n",
    "            detail=\"No file uploaded.\"\n",
    "        )\n",
    "\n",
    "    try:\n",
    "        # 2. Read the file bytes\n",
    "        audio_bytes = await file.read()\n",
    "\n",
    "        # 3. Attempt to decode the audio\n",
    "        #    We rely on torchaudio to detect that it's MP3 (or fail otherwise).\n",
    "        try:\n",
    "            audio, sr = torchaudio.load(io.BytesIO(audio_bytes), format=\"mp3\")\n",
    "        except Exception as e:\n",
    "            raise HTTPException(\n",
    "                status_code=status.HTTP_400_BAD_REQUEST,\n",
    "                detail=f\"Could not decode audio: {str(e)}\"\n",
    "            )\n",
    "\n",
    "        # 4. Resample to 16 kHz if necessary (Wav2Vec2 expects 16 kHz mono)\n",
    "        if sr != 16000:\n",
    "            resampler = torchaudio.transforms.Resample(sr, 16000)\n",
    "            audio = resampler(audio)\n",
    "            sr = 16000\n",
    "\n",
    "        # 5. Convert multi-channel to mono if needed\n",
    "        if audio.ndim > 1 and audio.shape[0] > 1:\n",
    "            audio = torch.mean(audio, dim=0)\n",
    "        # Remove any leftover first dimension\n",
    "        if audio.ndim > 1:\n",
    "            audio = audio.squeeze(0)\n",
    "\n",
    "        # 6. Preprocess and run model inference\n",
    "        input_values = processor(\n",
    "            audio,\n",
    "            sampling_rate=sr,\n",
    "            return_tensors=\"pt\"\n",
    "        ).input_values\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = model(input_values).logits\n",
    "\n",
    "        predicted_ids = torch.argmax(logits, dim=-1)\n",
    "        transcription = processor.decode(predicted_ids[0])\n",
    "\n",
    "        # 7. Calculate duration in seconds\n",
    "        duration_sec = audio.shape[-1] / sr\n",
    "\n",
    "        return {\n",
    "            \"transcription\": transcription,\n",
    "            \"duration\": str(duration_sec)\n",
    "        }\n",
    "\n",
    "    except HTTPException:\n",
    "        # Re-raise HTTPExceptions so FastAPI can handle them\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        # Catch-all for other errors\n",
    "        raise HTTPException(\n",
    "            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n",
    "            detail=f\"An unexpected error occurred: {str(e)}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3afad9b-b219-4421-ac40-de99be4de0c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting cv_decode2.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile cv_decode2.py\n",
    "\n",
    "#!/usr/bin/env python3\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def main():\n",
    "    # 1. Load the CSV file\n",
    "    csv_file = \"cv-valid-dev.csv\"\n",
    "    if not os.path.isfile(csv_file):\n",
    "        print(f\"Error: '{csv_file}' not found in the current folder.\")\n",
    "        return\n",
    "    \n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    # 2. Prepare to store transcriptions\n",
    "    transcriptions = []\n",
    "\n",
    "    # 3. Iterate over rows with a progress bar\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Transcribing files\"):\n",
    "        file_path = row[\"filename\"]  # e.g. \"cv-valid-dev/sample-000000.mp3\"\n",
    "        \n",
    "        # Check if the file exists\n",
    "        if not os.path.isfile(file_path):\n",
    "            print(f\"Warning: File '{file_path}' not found. Skipping.\")\n",
    "            transcriptions.append(\"\")\n",
    "            continue\n",
    "        \n",
    "        # Send POST request to the ASR endpoint with a 30s timeout\n",
    "        try:\n",
    "            with open(file_path, \"rb\") as f:\n",
    "                files = {\"file\": (os.path.basename(file_path), f, \"audio/mpeg\")}\n",
    "                response = requests.post(\n",
    "                    \"http://localhost:8001/asr\", \n",
    "                    files=files, \n",
    "                    timeout=(15, 30)  # Skip if processing takes more than 30s\n",
    "                )\n",
    "                \n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "                transcription = data.get(\"transcription\", \"\")\n",
    "            else:\n",
    "                print(f\"\\nError: Received status code {response.status_code} for file '{file_path}'\")\n",
    "                transcription = \"\"\n",
    "\n",
    "        except requests.exceptions.Timeout:\n",
    "            print(f\"\\nWarning: File '{file_path}' took longer than 30s. Skipping.\")\n",
    "            transcription = \"\"\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError: Could not process '{file_path}'. Reason: {str(e)}\")\n",
    "            transcription = \"\"\n",
    "        \n",
    "        transcriptions.append(transcription)\n",
    "    \n",
    "    # 4. Insert or update the generated text in a new column\n",
    "    df[\"generated_text\"] = transcriptions\n",
    "\n",
    "    # 5. Overwrite the same CSV file with the new column\n",
    "    df.to_csv(csv_file, index=False)\n",
    "    print(f\"\\nUpdated CSV file '{csv_file}' with new column 'generated_text'.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a575fd-43f8-4294-bd74-45de984cd81b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
